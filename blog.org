#+STARTUP: content
#+TITLE: Shane Sveller
#+AUTHOR: Shane Sveller
#+HUGO_BASE_DIR: .
#+HUGO_AUTO_SET_LASTMOD: t

* Pages
  :PROPERTIES:
  :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :noauthor true :nocomment true :nodate true :nopaging true :noread true
  :EXPORT_HUGO_MENU: :menu main
  :EXPORT_HUGO_SECTION: pages
  :VISIBILITY: children
  :END:

** DONE Hardware                                                  :@hardware:
   CLOSED: [2018-10-21 Sun 08:30]
   :PROPERTIES:
   :EXPORT_FILE_NAME: hardware
   :END:

My current custom-built gaming PC is as follows:

- Fractal Design R5 Black case
- Gigabyte GA-Z170X-Gaming GT motherboard
- Intel Core i7-6700k (Skylake) at 4.0GHz
- Corsair H110i GT liquid CPU cooler
- 32GB (4x8GB) Crucial Ballistix Elite DDR4-2666 RAM
- Asus Strix GeForce GTX 1080ti 11GB
- Samsung 950 Pro 256GB m.2 solid-state drive
- Samsung 850 Pro 512GB solid-state drive
- 2x Western Digital Red 1TB 7200rpm hard drive
- Windows 10 Pro x64
- Razer Naga mouse
- Razer Black Widow Chroma keyboard
- LG 34UM95-P 34" Ultrawide monitor
- Logitech Z-2300 speakers

I do all of my personal development work on:

- 2018 15" MacBook Pro
- 32GB DDR4-2400Mhz
- 2.9 GHz Intel Core i9 (6 cores)
- 1TB ApplePCI-E solid-state drive
- OSX 10.13 High Sierra

I have a file server:

- Synology 1513+
- Western Digital Red 4TB 7200rpm hard drive (5)

I have an Intel NUC virtualization server:

- Intel Skull Canyon NUC 6i7KYK
- 32GB (2x16GB) Crucial DDR4-2400
- 2x Crucial 500GB MX200 M.2 SSD

I have a Lenovo mid-tower virtualization server:

- Lenovo ThinkServer TS140
- Intel Xeon E3-1225 v3 3.2GHz
- 32GB (4x8GB) Crucial ECC DDR3-1600
- Western Digital Red 1TB 7200rpm (3)
- Intel I340-T4 (PCIE 2.0 x 4 lane, 4x1Gb NIC)

** TODO Software and Services                                     :@software:
   :PROPERTIES:
   :EXPORT_FILE_NAME: software-and-services
   :EXPORT_DATE: 2012-08-05
   :END:

   In no particular order, I endorse the following software, products and
   services on a personal level:

*** OSX Software

    - [[http://adium.im/][Adium]]
    - [[http://sprw.me/][Sparrow]] - no new development due to acquisition
      by Google is heartbreaking
    - [[http://mac.github.com][GitHub OSX client]]
    - [[http://reederapp.com/mac/][Reeder]] - Best RSS reader I've ever
      used, and it has a fantastic [[http://reederapp.com/ipad/][iOS port]]!
    - [[http://tapbots.com/tweetbot_mac/][TweetBot]] - Originally on
      [[http://tapbots.com/software/tweetbot/][iOS]], and is far and away my
      preferred Twitter client on both platforms. Beats the hell out of
      TweetDeck.
    - [[http://www.iterm2.com][iTerm 2]]
    - [[http://tmux.sourceforge.net][tmux]] - not OSX specific, but where I
      use it most

*** Cross-platform Software

    - [[http://dropbox.com/][Dropbox]] - still one of my favorite ways to
      keep files available on all my machines, including the iPad. Bonus:
      integration with
      [[http://pragprog.com/frequently-asked-questions/ebooks/read-on-desktop-laptop#dropbox][PragProg]]
      and
      [[http://shop.oreilly.com/category/customer-service/dropbox.do][O'Reilly]]
      for near-instant notificaiton of new e-book revisions!
    - [[http://sublimetext.com/2][SublimeText 2]] - see my 1-month
      impressions [[/posts/2012-08-05-sublimetext-2/][here]]!
    - [[http://spotify.com/][Spotify]] - the only streaming music service
      I'm still consistently glad I subscribe to. Works like a charm on
      Windows and OSX, and even has a
      [[http://spotify.com/us/download/previews/][Linux port]]!
    - [[https://kindle.amazon.com][Amazon Kindle]] - my preferred e-reader
      platform because it has great dedicated
      [[https://www.amazon.com/kindle-store-ebooks-newspapers-blogs/b/ref=r_ksl_h_i_gl?node=133141011][hardware
      readers]], and a reading app for pretty much
      [[https://www.amazon.com/gp/kindle/kcp/ref=r_kala_h_i_gl][every
      platform under the sun]].

*** Cloud/Web Apps

    - [[http://heroku.com/][Heroku]]
    - [[http://mint.com/][Mint]]
    - [[http://pinboard.in/][Pinboard]] - bookmarking service /ala/
      Delicious but without all the social trappings - and with great
      integration in Twitter clients/RSS readers!
    - [[http://pandora.com/][Pandora]] - I'm less happy with their variety
      than I wish, but still a great service

*** Screencasts

    - [[http://railscasts.com/][Railscasts]] - Ryan Bates has been
      consistently putting out focused, concise and informative screencasts
      on a variety of topics related to Ruby on Rails or programming at
      large. Congrats on a full year of doing RailsCasts full-time, Ryan!
      Happy to be a Pro subscriber.
    - [[https://peepcode.com/][PeepCode]] - May be less prolific than
      Railscasts, but the screencasts Geoffrey puts out are very meaty and
      I'm a big fan of the
      [[https://peepcode.com/products/play-by-play-tenderlove-ruby-on-rails][Play
      by Play series]].

*** Podcasts

    - [[http://ruby5.envylabs.com/][Ruby5]] is a great way to keep abreast
      of new or upcoming projects from the Ruby ecosystem
    - [[http://rubyrogues.com/][Ruby Rogues]] isn't nearly so bite-sized but
      dives deeper into subjects and often has very interesting guests

*** Reference Books

    - [[http://pragprog.com/][Pragmatic Programmers]] keeps publishing
      awesome books from great authors on exciting topics
    - [[http://www.manning.com/][Manning]] - I still buy the odd
      [[http://www.manning.com/about/meap][MEAP book]] on an upcoming
      technology and have yet to regret it
    - O'Reilly publishes most new books in an ebook format and sports
      integration with Dropbox for delivery of updated versions

*** E-Book Vendors

    - [[http://rpg.drivethrustuff.com/][DriveThruRPG]] has awesome sales on
      tabletop RPG rulebooks now and then - I've got a ton of
      [[http://www.white-wolf.com/classic-world-of-darkness][old]]/
      [[http://www.white-wolf.com/new-world-of-darkness][new World of
      Darkness]] and [[http://shadowrun4.com/][Shadowrun]], some
      Exalted/Trinity, and a dash of [[http://paizo.com/][Pathfinder]].

* Posts
  :PROPERTIES:
  :EXPORT_HUGO_SECTION: blog
  :END:

** Elixir                                                           :@elixir:
   :PROPERTIES:
   :VISIBILITY: children
   :END:
*** DONE Managing Elixir runtime version with ~asdf~     :asdf:elixir:erlang:
    CLOSED: [2017-12-23 Sat 22:30]
    :PROPERTIES:
    :EXPORT_AUTHOR: Shane Sveller
    :EXPORT_DATE: 2017-12-23
    :EXPORT_FILE_NAME: managing-elixir-runtime-version-with-asdf
    :END:

    An uncomfortably common problem when developing for a particular programming
    language is needing to deal with compatibility issues across different
    versions of the language runtime. Most often this means keeping individual
    projects tied to their then-current version of the language until such time
    that the project can address any compatibility issues with later language
    releases. To that end, Ruby developers are probably familiar with
    one of ~rbenv~, ~chruby~ or ~rvm~, for example. Elixir isn't much different
    in this regard.

    <!--more-->

    One available project that I find pretty promising is ~asdf~, which is
    self-described as:

    #+BEGIN_QUOTE
    [An] extendable version manager with support for Ruby, Node.js, Elixir, Erlang & more
    #+END_QUOTE

    It fulfills some of the same roles that ~rbenv~ and friends do, while
    supporting multiple languages and even other software tools in a fairly
    standardized way.

**** Installation

***** Homebrew

     #+BEGIN_SRC sh
       brew install asdf
     #+END_SRC

     Follow the instructions in the output, which you can read again with ~brew
     info asdf~ if you missed them. As of this writing, those instructions are:

     #+BEGIN_QUOTE
     Add the following line to your bash profile (e.g. ~/.bashrc, ~/.profile, or ~/.bash_profile)

     =source /usr/local/opt/asdf/asdf.sh=

     If you use Fish shell, add the following line to your fish config (e.g. ~/.config/fish/config.fish)

     =source /usr/local/opt/asdf/asdf.fish=
     #+END_QUOTE

***** Git

      You can follow the latest manual installation instructions from the
      project's [[https://github.com/asdf-vm/asdf/tree/8794210b8e7d87fcead78ae3b7b903cf87dcf0d6#setup][README]], but today it includes:

      #+BEGIN_SRC sh
        git clone https://github.com/asdf-vm/asdf.git ~/.asdf --branch v0.4.0

        # install shell hooks
        # I personally prefer `source` to `.`

        # bash users
        echo -e '\n. $HOME/.asdf/asdf.sh' >> ~/.bash_profile
        echo -e '\n. $HOME/.asdf/completions/asdf.bash' >> ~/.bash_profile

        # zsh users
        echo -e '\n. $HOME/.asdf/asdf.sh' >> ~/.zshrc
        echo -e '\n. $HOME/.asdf/completions/asdf.bash' >> ~/.zshrc

        # fish users
        echo 'source ~/.asdf/asdf.fish' >> ~/.config/fish/config.fish
        mkdir -p ~/.config/fish/completions; and cp ~/.asdf/completions/asdf.fish ~/.config/fish/completions
      #+END_SRC

****** Prerequisites

       At the time of writing, here are the prerequisites recommended to use
       ~asdf~, which can be installed with [[https://brew.sh/][Homebrew]]:

       #+BEGIN_SRC sh
         brew install autoconf automake coreutils \
              libtool libxslt libyaml openssl \
              readline unixodbc
       #+END_SRC

***** Install required asdf plugins

      You can check the available plugins, based on the open-source plugin index [[https://github.com/asdf-vm/asdf-plugins][here]]:

      #+BEGIN_SRC sh
        asdf plugin-list-all
      #+END_SRC

      After identifying desirable plugins:

     #+BEGIN_SRC sh
       asdf plugin-install erlang
       asdf plugin-install elixir
       # phoenix users will likely also want:
       asdf plugin-install nodejs
     #+END_SRC

**** Usage

     To install the latest Erlang and Elixir versions at the time of writing:

     #+BEGIN_SRC sh
       asdf install erlang 20.2
       asdf install elixir 1.5.3
     #+END_SRC

     Phoenix users will also want:

     #+BEGIN_SRC sh
       asdf list-all nodejs
       asdf install nodejs 9.3.0
     #+END_SRC

***** Checking available tool versions

      You can see what versions ~asdf~ currently supports for installation with
      this command:

      #+BEGIN_SRC sh
        # asdf list-all [plugin]
        asdf list-all erlang
        asdf list-all elixir
        asdf list-all nodejs
      #+END_SRC

      Each plugin is able to implement this behavior in its own way, so their
      behavior may vary. Some are able to directly examine the releases of the
      upstream language project, others require manual support within the ~asdf~
      plugin in question, and so may lag behind new releases.

***** Installing a specific Erlang patch version

     The author of ~asdf~, @HashNuke on GitHub, cleared up in [[https://github.com/asdf-vm/asdf-erlang/issues/48#issuecomment-339137374][this GitHub issue]]
     that any tagged release of Erlang can be installed with ~asdf-erlang~:

     #+BEGIN_QUOTE
     We already support it. You can do the following:

     =asdf install erlang ref:OTP-20.1.2=

     Where OTP-20.1.2 is a valid tag that you can find on
     https://github.com/erlang/otp/releases. You can also specify a commit sha
     or branch name if you insist on the latest super-powers.
     #+END_QUOTE

     As of this writing the latest release is [[https://github.com/erlang/otp/releases/tag/OTP-20.2.2][20.2.2]], so that can be installed
     like so:

     #+BEGIN_SRC sh
       asdf install erlang ref:OTP-20.2.2
       # set global default
       asdf global erlang ref:OTP-20.2.2
     #+END_SRC

***** Installing Elixir from ~master~

      If you'd like to use the latest and greatest features, such as the
      upcoming
      [[https://github.com/elixir-lang/elixir/blob/v1.6/CHANGELOG.md#code-formatter][~mix
      format~ command]] slated for inclusion in Elixir 1.6, you can install the
      current version of the elixir-lang/elixir repository's ~master~ branch:

      #+BEGIN_SRC sh
        asdf install elixir master
      #+END_SRC

      You can use this version all the time via ~asdf global~ or ~asdf local~,
      or on one-off commands by setting the ~ASDF_ELIXIR_VERSION~ environment
      variable to ~master~.

***** Per-project tool versions

      By using ~asdf local~, you can configure pre-project tool versions, which
      are persisted in a project-local ~.tool-versions~ file you may wish to
      include in your global ~.gitignore~. When revisiting a project later, you
      can run ~asdf install~ with no additional arguments to ensure that the
      project's desired software versions are available.

**** Keeping up to date

     To update ~asdf~ itself:

     #+BEGIN_SRC sh
       asdf update
     #+END_SRC

     To update ~asdf~ plugins:

     #+BEGIN_SRC sh
       # update all plugins
       asdf plugin-update --all
       # update individual plugin
       asdf plugin-update erlang
     #+END_SRC

**** Troubleshooting

     You can inspect where a particular version of a particular language is
     installed with ~asdf where~:

     #+BEGIN_SRC sh
       asdf where erlang 20.2
       # /Users/shane/.asdf/installs/erlang/20.2
     #+END_SRC

     You can make sure that newly-installed binaries (such as those installed by
     ~npm~) are detected by using ~asdf reshim~:

     #+BEGIN_SRC sh
       asdf reshim nodejs 9.3.0
       # no output
     #+END_SRC

     You can inspect which specific binary will be used in your current context,
     accounting for both global and local tool versions, with ~asdf which~:

     #+BEGIN_SRC sh
       asdf which erlang
       # /Users/shane/.asdf/installs/erlang/20.1/bin/erlang
     #+END_SRC

**** Other notable plugins

     Here are a few other asdf plugins I'm prone to using in the course of my
     infrastructure-focused work:

     - [[https://github.com/Banno/asdf-kubectl][kubectl]]
     - [[https://github.com/alvarobp/asdf-minikube][minikube]]
     - [[https://github.com/Banno/asdf-hashicorp][terraform]] (recently combined
       support for multiple Hashicorp tools in one plugin)

**** Alternatives

     There are many alternative options for
     [[https://elixir-lang.github.io/install.html][installing Elixir]]. Here are
     a few in no particular order and with no specific endorsement:

     - Homebrew (~brew install erlang elixir node~)
     - [[https://nixos.org/nix/][Nix package manager]] and ~nix-shell~ (blog post forthcoming!)
     - [[https://github.com/taylor/kiex][kiex]] and [[https://github.com/yrashk/kerl][kerl]]

**** Software/Tool Versions

     | Software | Version |
     |----------+---------|
     | OSX      | 10.12.6 |
     | asdf     |   0.4.0 |
     | Elixir   |   1.5.3 |
     | Erlang   |  20.2.2 |
     | Node.js  |   9.3.0 |

**** Reference Links                                               :noexport:

     - https://github.com/asdf-vm/asdf/tree/8794210b8e7d87fcead78ae3b7b903cf87dcf0d6#setup
     - https://github.com/asdf-vm/asdf-erlang/issues/48#issuecomment-339137374

*** Optimized Elixir Docker Images  :docker:elixir:phoenix:umbrella:noexport:
    :PROPERTIES:
    :EXPORT_AUTHOR: Shane Sveller
    :EXPORT_DATE: 2018-10-21
    :EXPORT_FILE_NAME: optimized-elixir-docker-images
    :END:

    Back in August of this year, I [[https://github.com/oestrich/ex_venture/pull/69][helped my friend Eric add a Docker image and
    Docker Compose environment]] for his multiplayer game server, [[https://exventure.org/][ExVenture]]. This
    was primarily based on an iteration of [[https://gist.github.com/shanesveller/d6e58ef40bbb1c11ca32ef0d62fda4a8][my own multi-stage Docker work]] back
    in February, which was for a Phoenix Umbrella app I'd been working on as a
    side project at the time.

    Let's pull back the curtain on my current active side project, which is also
    a text-based multiplayer game server like Eric's, and talk through the
    implications of and thought process behind each line of its Dockerfile.

    #+BEGIN_SRC dockerfile
      FROM elixir:1.7.3-alpine as builder

      # The nuclear approach:
      # RUN apk add --no-cache alpine-sdk
      RUN apk add --no-cache \
          gcc \
          git \
          make \
          musl-dev

      RUN mix local.rebar --force && \
          mix local.hex --force

      FROM builder as releaser

      WORKDIR /app
      ENV MIX_ENV=prod
      COPY mix.* /app/

      # Explicit list of umbrella apps
      RUN mkdir -p \
          /app/apps/chat \
          /app/apps/client \
          /app/apps/command_parser \
          /app/apps/game_world \
          /app/apps/gateway \
          /app/apps/metrics_exporter
      COPY apps/chat/mix.* /app/apps/chat/
      COPY apps/client/mix.* /app/apps/client/
      COPY apps/command_parser/mix.* /app/apps/command_parser/
      COPY apps/game_world/mix.* /app/apps/game_world/
      COPY apps/gateway/mix.* /app/apps/gateway/
      COPY apps/metrics_exporter/mix.* /app/apps/metrics_exporter/
      RUN mix deps.get --only prod
      RUN mix deps.compile

      COPY . /app/
      RUN mix release --env=prod --no-tar --name=ex_mud

      FROM alpine:3.8 as runner
      RUN apk add -U bash libssl1.0
      WORKDIR /app
      COPY --from=releaser /app/_build/prod/rel/ex_mud /app
      EXPOSE 5556 5559
      ENTRYPOINT ["/app/bin/ex_mud"]
      CMD ["foreground"]
    #+END_SRC

    <!--more-->

*** DONE Kubernetes Native Phoenix Apps: Introduction :docker:elixir:phoenix:umbrella:kubernetes:
    CLOSED: [2018-10-28 Sun 11:00]
    :PROPERTIES:
    :EXPORT_AUTHOR: Shane Sveller
    :EXPORT_DATE: 2018-10-28
    :EXPORT_FILE_NAME: kubernetes-native-phoenix-apps-introduction
    :END:

    I'm kicking off a new blog series that focuses on the intersection of Elixir
    and Kubernetes. This is becoming a more and more popular deployment target
    for companies and developers who don't find a comfortable fit with [[#alternate-deployment-tooling][other
    options]] that make different trade-offs.

    <!--more-->

    I've spent most of the last two years helping several companies leverage
    Kubernetes effectively, both as a direct employee on a systems/platform team
    and as a specialized consultant, and I'd like to share some of those
    learnings with the community that is nearest and dearest to my heart:
    Elixir. These companies varied in size and scope, but their chief
    commonality is that Kubernetes has proved to be an accelerant for their
    business goals.

    In particular, I consider Kubernetes an excellent target for deployment when
    dealing with teams that are shipping polygot solutions, teams who are
    managing multiple products without a dedicated team for each product,
    organizations looking to achieve better infrastructure density or
    standardization, or organizations who highly value infrastructure agility.

    Elixir's deployment story has come a long way since I started working with
    the language in 2015, but depending on your needs, there is still a *lot* of
    information to assimilate, and a lot of practices to synthesize into a
    unified, effective solution.

**** Prerequisites

    Infrastructure and deployment practices are not and can not be a
    one-size-fits-all problem space, so I'm going to focus on presenting an
    opinionated, focused, and polished approach that makes a few simplifying
    assumptions:

    - You have at least one Elixir app that leverages Phoenix for a web
      interface
    - You are already using, prepared to upgrade to, or are otherwise capable of
      using Distillery 2.x in your project
    - You are deploying your product on one of the infrastructure-as-a-service
      platforms that are suitable for use with production-grade Kubernetes,
      such as:
      - AWS via [[https://github.com/kubernetes/kops][Kops]]/[[https://aws.amazon.com/eks/][EKS]]
      - GCP via [[https://cloud.google.com/kubernetes-engine/][GKE]]
      - Azure via [[https://docs.microsoft.com/en-us/azure/aks/][AKS]]
    - Importantly, you *already have* a viable Kubernetes cluster in place with
      ~kubectl~ access ready to go
    - You are already comfortable with Kubernetes primitives or are capable of
      learning these from [[https://kubernetes.io/docs/][another reference]]

**** Planned series content
     - [[/blog/2018/10/28/kubernetes-native-phoenix-apps-part-1/][Part 1]]
       - New [[https://phoenixframework.org/][Phoenix]] 1.4 project
       - [[https://github.com/bitwalker/distillery/][Distillery]] 2
         - [[https://hexdocs.pm/distillery/config/runtime.html#config-providers][Configuration Providers]]
         - [[https://hexdocs.pm/distillery/guides/running_migrations.html][Database Migrations/Seeds]]
       - [[https://docs.docker.com/develop/develop-images/multistage-build/][Multi-stage Docker build]]
         - Dockerfile
         - Dockerignore
         - [[https://elixir-lang.org/getting-started/mix-otp/dependencies-and-umbrella-projects.html#umbrella-projects][Umbrella]] support
         - [[https://webpack.js.org/][Webpack]] assets
         - Caching image stages
     - Part 2
       - Running your application via [[https://docs.docker.com/compose/][Docker Compose]]
       - Running migrations/seeds via Docker Compose
       - Configuring secrets and runtime data via volumes
     - Part 3
       - Building your image on [[https://github.com/kubernetes/minikube][Minikube]]
       - [[https://github.com/helm/helm][Helm]] introduction
         - Deploy [[https://www.postgresql.org/][Postgres]] via [[https://github.com/helm/charts/tree/master/stable/postgresql][community Helm chart]]
       - Deploy your application via YAML
         - Configuring runtime data via ConfigMap
         - Configuring secrets vai Secret
         - Expose your application via Service
       - Running migrations/seeds via ~kubectl exec~
       - Running migrations/seeds via Job
     - Part 4
       - Deploying your application via Helm
         - [[https://github.com/futuresimple/helm-secrets][Helm-secrets]]
         - [[https://github.com/roboll/helmfile][Helmfile]]
       - Seeds during Helm install
       - Migrations during Helm upgrades
     - Part 5
       - Expose your application via Ingress
       - Managing DNS with [[https://github.com/kubernetes-incubator/external-dns][external-dns]]
       - Managing HTTPS with [[https://github.com/jetstack/cert-manager/][cert-manager]]
     - Part 6
       - Clustering your application with [[https://github.com/bitwalker/libcluster][libcluster]]
       - DNS- vs RBAC-based Kubernetes integration
       - Phoenix PubSub / Channels / Presence
       - ETS/Registry implications
     - Part 7
       - Local HTTPS via ~mix phx.gen.cert~ or [[https://github.com/FiloSottile/mkcert][mkcert]]
       - HTTP2 with [[https://ninenines.eu/docs/en/cowboy/2.5/guide/][Cowboy 2]]
       - Exposing HTTP2 via Service
       - HTTP2 Ingress ramifications
     - Part 8
       - HTTP2 with [[https://istio.io/][Istio]]
     - Part 9
       - Metrics with [[https://prometheus.io/][Prometheus]] and [[https://github.com/coreos/prometheus-operator][Prometheus Operator]]
       - Visualization with [[https://grafana.com/][Grafana]] and [[https://github.com/weaveworks/grafanalib][Grafanalib]]/[[https://github.com/grafana/grafonnet-lib][Grafonnet]]
       - Quality of service with Resource Request/Limits
       - Cluster-wide resource constraints with LimitRange
     - Part 10
       - Remote Observer via [[https://www.telepresence.io/][Telepresence]]

**** Off-topic Subjects
     This series will avoid deep coverage of a few topics that are worthy
     of their own separate coverage and will distract from the ideas being
     presented here:

     - CI/CD practices or tooling recommendations - I've worked with almost all
       of them by now other than GoCD, and I've assumed the position that these
       needs are heavily informed by your organizational structure and tolerance
       for certain constraints or limitations, and aren't able to be addressed
       in a generalized way
     - Automating the actual deployment workflows from SCM - similar to the
       above, it's hard to cover this adequately in a generic way
     - Kubernetes-as-development-environment tools - Tools like [[https://github.com/azure/draft][Draft]], [[https://github.com/GoogleContainerTools/skaffold/][Skaffold]],
       Knative, along with some of the other features of Telepresence, don't
       currently offer a compelling use-case for me. I've attempted several
       iterations where I've tried to evaluate them in earnest, and I
       unfortunately found them to be feature-incomplete, unreliable, hard to
       triage without RTFS, and high-friction to use.

     Additionally, I will avoid covering subjects that I consider to be
     out-of-scope:
     - Elixir/Phoenix fundamentals
     - Elixir/Phoenix development environment
     - Kubernetes fundamentals
     - A direct treatment of the pros/cons of using containers with the BEAM
     - Individual merits of alternate container schedulers (K8s vs GKE/AKS/EKS
       vs OpenShift vs ECS vs Mesos vs Nomad)
     - Hot code upgrades in the context of Docker/Kubernetes

**** Other Caveats
     This series will avoid documenting certain practices that I strongly
     consider to be development or deployment antipatterns. I'm aware that there
     are some situations where they are more appropriate, or at very least more
     expedient under the constraints in play, but these are generally to be
     avoided if you have the opportunity to choose otherwise.

     - Long-term use of Docker images and long-lived containers as your actual
       development environment - stick with native development practices for
       best productivity
     - Single-stage Docker images which include a full development/compilation
       toolchain in the final product
     - Building Docker images *on* your Kubernetes cluster by mounting the
       Docker daemon's socket into a container (with a partial exception for the
       Minikube phase)
     - Raw YAML templates as a long-term solution for managing Kubernetes
       workloads
     - Tools such as Kompose which translate directly from ~docker-compose.yml~
       to Kubernetes resource manifests
     - Namespaces and RBAC as your sole boundary between logical environments
       (such as dev/staging/production as implied by ~MIX_ENV~ conventions)

**** Alternate Deployment Tooling
     :PROPERTIES:
     :CUSTOM_ID: alternate-deployment-tooling
     :END:

   - Platform-as-a-service offerings
     - [[https://github.com/dokku/dokku][Dokku]]
     - [[https://github.com/flynn/flynn][Flynn]]
     - [[https://gigalixir.com/][Gigalixir]]
     - [[https://github.com/nanobox-io/nanobox][Nanobox]]
     - [[https://www.heroku.com/][Heroku]]
   - Imperative tools which espouse a Capistrano-like workflow
     - [[https://github.com/annkissam/akd][akd]]
     - [[https://github.com/labzero/bootleg][bootleg]]
     - [[https://github.com/edeliver/edeliver][edeliver]]
     - [[https://github.com/hashrocket/gatling][gatling]] (possibly unmaintained)
   - Specialized configuration management
     - [[https://github.com/HashNuke/ansible-elixir-stack][ansible-elixir-stack]]

*** DONE Kubernetes Native Phoenix Apps: Part 1 :docker:elixir:phoenix:umbrella:kubernetes:
    CLOSED: [2018-10-28 Sun 14:15]
    :PROPERTIES:
    :EXPORT_AUTHOR: Shane Sveller
    :EXPORT_DATE: 2018-10-26
    :EXPORT_FILE_NAME: kubernetes-native-phoenix-apps-part-1
    :END:

    As described in the introductory post, this article will briefly describe
    the installation of Distillery 2 as well as including a deeper philosophical
    and technical explanation of how I structure multi-stage Docker images for
    Elixir/Phoenix applications.

    <!--more-->

    Published articles in this series:

    - [[/blog/2018/10/28/kubernetes-native-phoenix-apps-introduction/][Introduction]]
    - Part 1 (this post)

**** Our Application

     The [[https://github.com/shanesveller/kube-native-phoenix][application]] we're going to be working with throughout this series was
     created as follows:

     - Phoenix 1.4 (RC2 at the time of writing)
     - Umbrella application
     - Using default components (Ecto, Postgres, Webpack)

     Its actual content and functionality will intentionally be kept very
     sparse, other than to demonstrate certain common scenarios, such as native
     dependencies of well-known Hex packages.

**** Installing Distillery 2

     Generally speaking, we'll closely follow the existing Distillery 2
     [[https://hexdocs.pm/distillery/introduction/installation.html][installation guide]]. Paul and the other contributors have produced very
     high-quality documentation as part of the 2.x release cycle. I'll call
     specific attention to a few sections of these guides:

     - [[https://hexdocs.pm/distillery/introduction/installation.html][Installation guide]]
     - [[https://hexdocs.pm/distillery/introduction/walkthrough.html][Walkthrough]]
     - [[https://hexdocs.pm/distillery/introduction/umbrella_projects.html][Umbrella Projects]]
     - [[https://hexdocs.pm/distillery/guides/phoenix_walkthrough.html][Phoenix guide]]
     - [[https://hexdocs.pm/distillery/guides/working_with_docker.html][Deploying with Docker]]

     The last guide is perhaps where we will diverge the most from the upstream
     documentation. As I mentioned previously, this blog series will present an
     opinionated and optimized experience, so we're going to make a few
     different choices in how to structure our Docker image.

     Before continuing, please make sure that you have completed the
     installation of Distillery within your application, and that you can
     successfully run ~mix release~ and get a working application.

     For an example of what this looks like in our live application, please see
     the git tree at commits ~4b2e2cb..aa6c54e~ [[https://github.com/shanesveller/kube-native-phoenix/compare/4b2e2cb...aa6c54e][here]].

**** Creating our first Docker image

     While there are many options and many opinions on how to construct an
     optimal Docker image, here are my personal recommended priorities:

     - Strict compatibility with vanilla ~docker build~ commands on a recent
       version of the Docker daemon (~17.05+), which implies compatibility with
       a broad variety of CI/CD tools and environments
     - Smallest reasonable resulting image, achieved primarily through
       multi-stage builds and intentional choice of base images
     - High cache hit rate during iterative builds
     - No mixing of runtimes in build stages, i.e. no adding Node.js to an
       Elixir base image
     - Alpine Linux-based, with a pivot to the ~-slim~ images when absolutely
       necessary
     - Final image should have minimal system-level packages installed and rely
       on Distillery's ability to package the Erlang runtime system with a
       release

***** Dockerfile

      As mentioned, we're targeting ~docker build~ compatibility rather than one
      of the other, possibly more sophisticated approaches.

      Let's see the complete file first and then walk through it together in
      small steps.

      #+BEGIN_SRC dockerfile -n 1
        # docker build -t kube_native:builder --target=builder .
        FROM elixir:1.7.3-alpine as builder
        RUN apk add --no-cache \
            gcc \
            git \
            make \
            musl-dev
        RUN mix local.rebar --force && \
            mix local.hex --force
        WORKDIR /app
        ENV MIX_ENV=prod

        # docker build -t kube_native:deps --target=deps .
        FROM builder as deps
        COPY mix.* /app/
        # Explicit list of umbrella apps
        RUN mkdir -p \
            /app/apps/kube_native \
            /app/apps/kube_native_web
        COPY apps/kube_native/mix.* /app/apps/kube_native/
        COPY apps/kube_native_web/mix.* /app/apps/kube_native_web/
        RUN mix do deps.get --only prod, deps.compile

        # docker build -t kube_native:frontend --target=frontend .
        FROM node:10.12-alpine as frontend
        WORKDIR /app
        COPY apps/kube_native_web/assets/package*.json /app/
        COPY --from=deps /app/deps/phoenix /deps/phoenix
        COPY --from=deps /app/deps/phoenix_html /deps/phoenix_html
        RUN npm ci
        COPY apps/kube_native_web/assets /app
        RUN npm run deploy

        # docker build -t kube_native:releaser --target=releaser .
        FROM deps as releaser
        COPY . /app/
        COPY --from=frontend /priv/static apps/kube_native_web/priv/static
        RUN mix do phx.digest, release --env=prod --no-tar

        # docker run -it --rm elixir:1.7.3-alpine sh -c 'head -n1 /etc/issue'
        FROM alpine:3.8 as runner
        RUN addgroup -g 1000 kube_native && \
            adduser -D -h /app \
              -G kube_native \
              -u 1000 \
              kube_native
        RUN apk add -U bash libssl1.0
        USER kube_native
        WORKDIR /app
        COPY --from=releaser /app/_build/prod/rel/kube_native_umbrella /app
        EXPOSE 4000
        ENTRYPOINT ["/app/bin/kube_native_umbrella"]
        CMD ["foreground"]
      #+END_SRC

      Code samples are described by their preceding text below.

****** Build environment

       First, we prepare a build stage named ~builder~ with the basic
       prerequisites of an Elixir development environment, including some fairly
       universally-required tooling for native extensions. This is where we'll
       insert any additional development packages needed to compile certain Hex
       dependencies in the future.

       Note also that we don't get Hex or Rebar automatically installed with
       this base image, and need to trigger those installations ourselves.

       Finally, we'll be building our project inside the ~/app~ working
       directory and defaulting to the ~prod~ Mix environment during Hex package
       compilation. *This image is not intended for development purposes
       whatsoever* and is fairly unsuitable for that use-case.

       #+BEGIN_SRC dockerfile -n 2
         FROM elixir:1.7.3-alpine as builder
         RUN apk add --no-cache \
             gcc \
             git \
             make \
             musl-dev
         RUN mix local.rebar --force && \
             mix local.hex --force
         WORKDIR /app
         ENV MIX_ENV=prod
       #+END_SRC

       I'm using a specific tagged Elixir release here, targeting the ~-alpine~
       variant to build on top of Alpine Linux. The maintainers of this
       "official" Docker image are not affiliated with Plataformatec or Erlang
       Solutions, and one downside of this image stream is that they treat
       certain tags as mutable.

       At different calendar dates, the ~1.7.3-alpine~ image tag has included
       differing versions of the underlying Erlang runtime. One way to hedge
       against this would be to be more precise in our FROM line:

       #+BEGIN_SRC dockerfile
         FROM elixir:1.7.3-alpine@sha256:4eb30b05d0acc9e8821dde339f0e199ae616e0e9921fd84822c23fe6b1f81b6d
       #+END_SRC

       You can determine the digest to include by running ~docker images
       --digests elixir~.

       While it would be totally valid to install and compile both Erlang and
       Elixir from source during this build phase, I do not consider this to be
       at all necessary or a particularly valuable effort for most companies or
       scenarios. Doing so requires you to absorb the maintenance burden of
       "keeping up with the Joneses" and incorporating any necessary security
       patches yourself, tracking the current release versions, and
       understanding their own build-time dependencies.

       If you find yourself with a requirement that cannot be satisfied under
       Alpine Linux, or feel an anti-affinity for Alpine, or an affinity for
       Debian, using a ~-slim~ base image variant will be largely identical to
       this process. Start with replacing ~apk~ commands with their semantic
       equivalent using ~apt-get~ (because ~apt~ makes no stability guarantees
       about its input/output). You'll potentially have broader compatibility
       with some corners of the software industry, at the cost of a slightly
       larger runtime image.

****** Hex Dependencies

       Next we acquire and compile all known Hex dependencies. This slightly
       verbose layering structure allows us to get a very high cache hit rate
       during Docker builds, because our dependencies are some of the slowest
       and least-frequently changing portions of our application development
       work.

       Note here that for an umbrella application, we also need to descend into
       each umbrella app and include its ~mix.exs~ content as well. In a
       non-umbrella application, it's likely sufficient to only include the
       highlighted lines.

       Lines 17-21 are an unfortunate necessity for Umbrella applications, as
       the ~COPY~ directive for Dockerfiles doesn't support multiple
       destinations per the [[https://docs.docker.com/engine/reference/builder/#copy][documentation]], only multiple sources. As you add
       more applications to your umbrella, new lines will need to be added here.
       (I'm working on a Mix task library that will embody this and other
       operational knowledge, which will be released to Hex in the coming
       weeks.)

       Now, this seems like an awful lot of ceremony, doesn't it? Here's the
       payoff: without a technique that is similar to this in spirit,
       application-level changes such as new behavior in a Phoenix controller or
       new markup in a view template will *bust the Docker build cache* and
       require all of the Hex dependencies to be downloaded and compiled anew.

       This is a very common pattern across many programming languages when
       creating Docker images, not just Elixir, so I'm satisfied with including
       it here. You'll also see it again in the next section.

       #+BEGIN_SRC dockerfile +n 2 :hl_lines 1-3,10
         # docker build -t kube_native:deps --target=deps .
         FROM builder as deps
         COPY mix.* /app/
         # Explicit list of umbrella apps
         RUN mkdir -p \
           /app/apps/kube_native \
           /app/apps/kube_native_web
         COPY apps/kube_native/mix.* /app/apps/kube_native/
         COPY apps/kube_native_web/mix.* /app/apps/kube_native_web/
         RUN mix do deps.get --only prod, deps.compile
       #+END_SRC

****** NPM/Asset Dependencies

       Similar to how we constructed the ~deps~ phase just above, we're pulling
       in a language-specific but otherwise unadorned base image to do the heavy
       lifting, as I don't wish to maintain or even be particularly
       familiar with packing Node when it's not a *runtime* dependency.

       We grab the *package.json* and *package-lock.json* files from our project
       to describe our JavaScript-ecosystem dependencies, and also bundle in the
       Javascript assets that are included with our previously-acquired Hex
       packages. Following that, we use the somewhat-recent ~npm ci~ command,
       which is optimal for the scenario where we're not looking to upgrade or
       otherwise change our JS dependencies, merely reproduce them as-is.

       After the NPM dependency tree is resolved, we pull in the rest of our
       locally-authored frontend content and then use an NPM task to run a
       production-friendly Webpack build of our assets.

       #+BEGIN_SRC dockerfile +n 2
         # docker build -t kube_native:frontend --target=frontend .
         FROM node:10.12-alpine as frontend
         WORKDIR /app
         COPY apps/kube_native_web/assets/package*.json /app/
         COPY --from=deps /app/deps/phoenix /deps/phoenix
         COPY --from=deps /app/deps/phoenix_html /deps/phoenix_html
         RUN npm ci
         COPY apps/kube_native_web/assets /app
         RUN npm run deploy
       #+END_SRC

****** Compile release

       Now it's time to tie all of this together into a Distillery release! We
       pull in our Elixir dependencies from the previous phase as our new base
       image, and then include only the compiled assets from the Node stage in
       our ~/priv/static~ directory. ~mix phx.digest~ takes those in and
       fingerprints them, and then finally we run ~mix release~ to build our
       package without ~tar~ring it up, as we'd just have to unpack again in the
       next and final stage.

       #+BEGIN_SRC dockerfile +n 2
         # docker build -t kube_native:releaser --target=releaser .
         FROM deps as releaser
         COPY . /app/
         COPY --from=frontend /priv/static apps/kube_native_web/priv/static
         RUN mix do phx.digest, release --env=prod --no-tar
       #+END_SRC

****** Build runtime image

       Here's how we achieve our minimal runtime image sizes. At the time of
       writing, the previous stage produces a Docker image weighing at about
       240MB, and with 20 separate image layers. For our final image, we start
       over from a compatible release of Alpine Linux. It's a strong
       recommendation that whenever possible, we not run containerized processes
       as the root user within the image, so we create a static group and user
       for this application, each with ID ~1000~, and switch to that user. The
       particular number likely will not matter up until the point that you need
       to reconcile file ownership across Docker volumes or between host and
       container.

       We pull in the uncompressed release built in the previous stage, expose
       the default Phoenix port, and set our ~ENTRYPOINT~ to launch the script
       provided by Distillery. The ~CMD~ directive tells the image that by
       default it should launch the application in the foreground without
       interactivity.

       We'll see later in the series that this opens up the opportunity to run
       custom commands more easily within our image, specified at runtime,
       without altering the image.

       #+BEGIN_SRC dockerfile +n 2
         # docker run -it --rm elixir:1.7.3-alpine sh -c 'head -n1 /etc/issue'
         FROM alpine:3.8 as runner
         RUN addgroup -g 1000 kube_native && \
             adduser -D -h /app \
               -G kube_native \
               -u 1000 \
               kube_native
         RUN apk add -U bash libssl1.0
         USER kube_native
         WORKDIR /app
         COPY --from=releaser /app/_build/prod/rel/kube_native_umbrella /app
         EXPOSE 4000
         ENTRYPOINT ["/app/bin/kube_native_umbrella"]
         CMD ["foreground"]
       #+END_SRC

***** Dockerignore

     We'll continue the process of Dockerizing this Phoenix application with an
     oft-forgotten step: the ~.dockerignore~ file. This file will feel similar to
     the syntax of a ~.gitignore~ file, but does not intentionally mimic its
     structure [[https://docs.docker.com/engine/reference/builder/#dockerignore-file][as documented by Docker]].

     We can start ourselves on good footing by copying the existing ~.gitignore~
     provided by the ~phx.new~ task when we started our project:

     #+BEGIN_SRC shell
       echo '# Default gitignore content' > .dockerignore
       cat .gitignore >> .dockerignore
     #+END_SRC

     And next we'll customize it for our needs by adding the following content:

     #+BEGIN_SRC gitignore -n :hl_lines 2,6,8,11-14
       # Developer tools
       .git
       .tool-versions

       # Umbrella structure
       apps/**/config/*.secret.exs
       apps/**/node_modules
       apps/**/priv/cert
       apps/**/priv/static

       # Docker
       .dockerignore
       Dockerfile
       docker-compose.yml
     #+END_SRC

     The value in a well-formed ~.dockerignore~ file is two-fold in my eyes. It
     prevents local content that shouldn't be persisted from appearing in Docker
     images that were built locally, such as secrets, tooling/editor artifacts,
     or compiled content like our static assets. (We're just going to recompile
     those in a build stage, anyway!) It also minimizes the local changes that
     will contribute to a cache miss when building updated versions of an
     existing Docker image.

     The logic here is fairly subjective, but I feel that the following tasks
     should not /inherently/ cause a fresh image build:

     - Git commits persisting your changes, without other filesystem changes
       (line 2)
     - Non-semantic changes to how we define the Dockerfile, such as whitespace
       or comments (lines 12-13)
       - Docker will automatically cache-bust for us if the changes are meaningful
     - Changes to a Docker Compose environment definition (line 14)
     - Changes to development-only or gitignored secrets files (lines 6, 8)

***** Caveats

      This approach comes with a lot of benefits, but it was at least one
      significant drawback - "cold" builds, that don't have applicable caches
      present, are just as slow as a single-stage linear approach. Thankfully,
      this can be mitigated via workflow changes.

      If you build your images with this command or similar, you'll notice that
      you also get some "dangling" images on your Docker host:

      #+BEGIN_SRC shell
        docker build -t kube_native:$git_sha .
      #+END_SRC

      These images are ephemeral outputs of the stages of our build, and can be
      intentionally captured as a differently-tagged image. One thing this
      avoids, other than ambiguity in ~docker images~ command output, is that
      these images would then no longer be cleared by mechanisms like ~docker
      system prune~, without the ~-a~ flag.

      These preliminary stage images could even be pushed to the same Docker
      image registry that your runtime image goes to, so that multiple
      developers can share the existing cached work without repeating it until
      necessary.

      There were comments throughout the above Dockerfile section, but here's
      the alternate workflow I'm proposing:
      #+BEGIN_SRC shell
        docker build -t kube_native:builder --target=builder .
        docker build -t kube_native:deps --target=deps .
        docker build -t kube_native:frontend --target=frontend .
        docker build -t kube_native:releaser --target=releaser .
        docker build -t kube_native:$git_sha .
        docker tag kube_native:builder my.registry.com/kube_native:builder
        docker push my.registry.com/kube_native:builder
        docker tag kube_native:deps my.registry.com/kube_native:deps
        docker push my.registry.com/kube_native:deps
        # ...
        docker push my.registry.com/kube_native:$git_sha
      #+END_SRC

      This is verbose, but precise, and ripe for automation via Makefile, Mix
      tasks, etc. You can also introduce a growing list of ~--cache-from~ flags
      to the above commands to specify what images are considered "upstream" of
      a given target.

      Other developers, and your CI/CD systems, can first ~docker pull~ the
      above tagged images to speed up their local builds. Anecdotally, I saw
      Google Cloud Builder save around 2/3 of my build time by following this
      technique.

**** Code Checkpoint

     The work presented in this post is reflected in git commit d239377
     available [[https://github.com/shanesveller/kube-native-phoenix/tree/d239377bfbc910c455b2498d2e3bdfbe6642e857][here]]. You can compare these changes to the initial commit [[https://github.com/shanesveller/kube-native-phoenix/compare/4b2e2cb...d239377][here]].

**** Appendix

***** Software/Tool Versions
      | Software   |    Version |
      |------------+------------|
      | Distillery |     2.0.10 |
      | Docker     | 18.06.1-ce |
      | Elixir     |      1.7.3 |
      | Erlang     |     21.1.1 |
      | Phoenix    |   1.4-rc.2 |

***** Identifying Alpine base release

      #+BEGIN_SRC shell
        docker run -it --rm elixir:1.7.3-alpine sh -c 'head -n1 /etc/issue'
      #+END_SRC

***** Shell Transcript                                             :noexport:
      #+BEGIN_SRC shell
        # Prerequisites
        ## PostgreSQL
        brew install postgresql
        brew services start postgresql
        ## Elixir
        asdf update
        asdf plugin-update erlang
        asdf plugin-update elixir
        asdf install erlang 21.1.1
        asdf global erlang 21.1.1
        asdf install elixir 1.7.3-otp-21
        asdf global elixir 1.7.3-otp-21

        ## Phoenix
        mix archive.install hex phx_new 1.4.0-rc.2

        # Create Project
        mix phx.new kube_native --binary-id --umbrella
        cd kube_native_umbrella
        git init
        git add .
        git commit -am 'Initial commit'
        ## Edit config/dev.exs, delete username/password/hostname

        # Release
        mix hex.info distillery
        ## Edit root mix.exs
        mix do deps.get, deps.compile
        mix release.init

        # Dockerize
        sed -e 's/^\///' .gitignore > .dockerignore
        touch Dockerfile
        docker-show-context
      #+END_SRC

      #+BEGIN_SRC gitignore
        # .dockerignore content

        # Developer tools
        .git
        .tool-versions

        # Umbrella
        apps/**/config/*.secret.exs
        apps/**/node_modules
        apps/**/priv/cert
        apps/**/priv/static

        # Docker
        .dockerignore
        Dockerfile
        docker-compose.yml
      #+END_SRC

      #+BEGIN_SRC dockerfile
        FROM elixir:1.7.3-alpine as builder
        RUN apk add --no-cache \
            gcc \
            git \
            make \
            musl-dev
        RUN mix local.rebar --force && \
            mix local.hex --force
        WORKDIR /app
        ENV MIX_ENV=prod
        # docker build -t kube_native:builder --target=builder .

        FROM builder as deps
        COPY mix.* /app/
        # Explicit list of umbrella apps
        RUN mkdir -p \
            /app/apps/kube_native \
            /app/apps/kube_native_web
        COPY apps/kube_native/mix.* /app/apps/kube_native/
        COPY apps/kube_native_web/mix.* /app/apps/kube_native_web/
        RUN mix do deps.get --only prod, deps.compile
        # docker build -t kube_native:deps --target=deps .

        FROM node:10.12-alpine as frontend
        WORKDIR /app
        COPY apps/kube_native_web/assets/package*.json /app/
        COPY --from=deps /app/deps/phoenix /deps/phoenix
        COPY --from=deps /app/deps/phoenix_html /deps/phoenix_html
        RUN npm ci
        COPY apps/kube_native_web/assets /app
        RUN npm run deploy
        # docker build -t kube_native:frontend --target=frontend .

        FROM deps as releaser
        COPY . /app/
        COPY --from=frontend /priv/static apps/kube_native_web/priv/static
        RUN mix do phx.digest, release --env=prod --no-tar
        # docker build -t kube_native:releaser --target=releaser .

        # docker run -it --rm elixir:1.7.3-alpine sh -c 'head -n1 /etc/issue'
        FROM alpine:3.8 as runner
        RUN apk add -U bash libssl1.0
        WORKDIR /app
        COPY --from=releaser /app/_build/prod/rel/kube_native_umbrella /app
        EXPOSE 4000
        ENTRYPOINT ["/app/bin/kube_native"]
        CMD ["foreground"]
      #+END_SRC

      #+BEGIN_SRC elixir
        # Config providers
        # https://hexdocs.pm/distillery/2.0.10/config/runtime.html#config-providers
        # https://hexdocs.pm/distillery/2.0.10/config/runtime.html#mix-config-provider

        # rel/config.exs
        environment :prod do
          set include_erts: true
          set include_src: false
          set cookie: :hunter2

          # highlight below
          set config_providers: [
            {Mix.Releases.Config.Providers.Elixir, ["${RELEASE_ROOT_DIR}/etc/config.exs"]}
          ]
          set overlays: [
            {:copy, "rel/config/config.exs", "etc/config.exs"}
          ]
        end

        release :kube_native_umbrella do
          set version: current_version(:kube_native) # highlight
          set applications: [
            :runtime_tools,
            kube_native: :permanent,
            kube_native_web: :permanent
          ]
        end

        # rel/config/config.exs
        config :kube_native, KubeNative.Repo,
          url: System.get_env("DATABASE_URL")

        # apps/kube_native_web/config/prod.exs
        config :phoenix, :serve_endpoints, true
      #+END_SRC

      Migrations:
      #+BEGIN_SRC elixir
        defmodule KubeNative.ReleaseTasks do
          @start_apps [
            :crypto,
            :ssl,
            :postgrex,
            :ecto,
            :telemetry
          ]

          @repos Application.get_env(:kube_native, :ecto_repos, [])

          def migrate(_argv) do
            start_services()

            run_migrations()

            stop_services()
          end

          def seed(_argv) do
            start_services()

            run_migrations()

            run_seeds()

            stop_services()
          end

          defp start_services do
            IO.puts("Starting dependencies..")
            # Start apps necessary for executing migrations
            Enum.each(@start_apps, &Application.ensure_all_started/1)

            # Start the Repo(s) for app
            IO.puts("Starting repos..")
            Enum.each(@repos, & &1.start_link(pool_size: 2))
          end

          defp stop_services do
            IO.puts("Success!")
            :init.stop()
          end

          defp run_migrations do
            Enum.each(@repos, &run_migrations_for/1)
          end

          defp run_migrations_for(repo) do
            app = Keyword.get(repo.config, :otp_app)
            IO.puts("Running migrations for #{app}")
            migrations_path = priv_path_for(repo, "migrations")
            Ecto.Migrator.run(repo, migrations_path, :up, all: true)
          end

          defp run_seeds do
            Enum.each(@repos, &run_seeds_for/1)
          end

          defp run_seeds_for(repo) do
            # Run the seed script if it exists
            seed_script = priv_path_for(repo, "seeds.exs")

            if File.exists?(seed_script) do
              IO.puts("Running seed script..")
              Code.eval_file(seed_script)
            end
          end

          defp priv_path_for(repo, filename) do
            app = Keyword.get(repo.config, :otp_app)

            repo_underscore =
              repo
              |> Module.split()
              |> List.last()
              |> Macro.underscore()

            priv_dir = "#{:code.priv_dir(app)}"

            Path.join([priv_dir, repo_underscore, filename])
          end
        end
      #+END_SRC
      #+BEGIN_SRC shell
        mix run -e "KubeNative.ReleaseTasks.migrate([])"
        mix run -e "KubeNative.ReleaseTasks.seed([])"
      #+END_SRC
      #+BEGIN_SRC shell
        #!/bin/sh

        release_ctl eval --mfa "KubeNative.ReleaseTasks.migrate/1" --argv -- "$@"
      #+END_SRC
      #+BEGIN_SRC elixir
        # rel/config.exs
        release :kube_native do
          # ...
          set commands: [
            migrate: "rel/commands/migrate.sh",
            seed: "rel/commands/seed.sh",
          ]
        end
      #+END_SRC
      #+BEGIN_SRC shell
        docker-compose run --rm kube_native migrate
      #+END_SRC
      #+BEGIN_SRC shell
        cd apps/kube_native_web
        mix phx.gen.cert
      #+END_SRC
      #+BEGIN_SRC elixir
        # apps/kube_native_web/config/dev.exs
        # ...
        config :kube_native_web, KubeNativeWeb.Endpoint,
          http: [port: 4000],
          https: [
            port: 4001,
            cipher_suite: :strong,
            certfile: "priv/cert/selfsigned.pem",
            keyfile: "priv/cert/selfsigned_key.pem"
          ],
        # ...
      #+END_SRC
      #+BEGIN_SRC yaml
        steps:
          - name: 'gcr.io/cloud-builders/docker'
            args: ['build', '-t', 'gcr.io/$PROJECT_ID/kube_native:$COMMIT_SHA', '.']
          - name: 'gcr.io/cloud-builders/docker'
            args: ['tag', 'gcr.io/$PROJECT_ID/kube_native:$COMMIT_SHA', 'gcr.io/$PROJECT_ID/kube_native:latest']
        images:
          - 'gcr.io/$PROJECT_ID/kube_native:$COMMIT_SHA'
          - 'gcr.io/$PROJECT_ID/kube_native:latest'
      #+END_SRC
      #+BEGIN_SRC gitignore

      #+END_SRC
      #+BEGIN_SRC shell
        # https://cloud.google.com/cloud-build/docs/build-debug-locally
        cloud-build-local -config=cloudbuild.yaml -substitutions=COMMIT_SHA=(hub rev-parse HEAD) --dryrun=false .
        gcloud builds submit --config=cloudbuild.yaml --substitutions=COMMIT_SHA=(hub rev-parse HEAD) .
      #+END_SRC
      #+BEGIN_SRC shell
        mkdir -p .deployment/chart
        cd .deployment/chart
        helm create kube_native
      #+END_SRC
      #+BEGIN_SRC shell
        helm init --upgrade --skip-refresh --history-max 10 --service-account tiller --wait --replicas=2 -i gcr.io/kubernetes-helm/tiller:v2.11.0
        helm install stable/postgresql --name kube-native-postgresql --set 'imageTag=10.5-alpine,postgresDatabase=kube-native,postgresPassword=kube-native,postgresUser=kube-native'
      #+END_SRC
      https://hexdocs.pm/libcluster/Cluster.Strategy.Gossip.html#content
      #+BEGIN_SRC elixir
        use Mix.Config

        config :libcluster,
          debug: true
      #+END_SRC

** Emacs                                                             :@emacs:
*** DONE Blogging with org-mode and ox-hugo      :hugo:netlify:org:spacemacs:
    CLOSED: [2018-02-13 Tue 12:30]
    :PROPERTIES:
    :EXPORT_DATE: 2018-02-13
    :EXPORT_FILE_NAME: blogging-with-org-mode-and-ox-hugo
    :END:

    I've recently assembled a workflow for blogging with [[https://gohugo.io/][Hugo]], [[http://orgmode.org/][org-mode]], and
    [[https://www.netlify.com/][Netlify]] via a single ~.org~ document, with live reload during writing and ~git
    push~ driven deployments.

    <!--more-->

**** Recommended Reading                                   :noexport:rewrite:

     Before pursing a workflow like this, you should be somewhat familiar with
     the separate behaviors of [[https://www.gnu.org/software/emacs/][Emacs]], [[http://orgmode.org/][org-mode]], org's [[http://orgmode.org/manual/Exporting.html#Exporting][Exporting]] functionality,
     and the [[https://gohugo.io][Hugo]] static site generator.

**** Requirements

     I've detailed my current environment in the
     [[#ox-hugo-software-tool-versions][Software/Tool Versions]] appendix below.
     Strictly speaking, the hard requirements of the
     [[https://melpa.org/#/ox-hugo][ox-hugo]] package are:

     - Emacs 24.4+
     - org-mode 9.0+

     To use the ~git~-based publishing part of this workflow, you'll also need:

     - A GitHub account (free or otherwise)
     - A Netlify account (free or otherwise)

**** Features

     - Compose and organize content in a single Org file
     - Each post automatically gets a Table of Contents if sub-headings are present
     - Preview in your local browser including live-reload behavior
     - Syntax highlighting, including custom line numbers and line highlights
     - Manage draft / publication status
     - Manage categories and tags
     - Manage post aliases
     - Manage custom front-matter
     - Publish via ~git push~, perhaps via [[https://magit.vc/][Magit]]
     - Free hosting via Netlify (dear Netlify, please let me give you money
       without a multi-user/Pro account!)
     - Free HTTPS via Netlify's Lets Encrypt integration

**** Installation

     I've included snippets for ~use-package~ users and Spacemacs users - others
     should look at the [[https://github.com/kaushalmodi/ox-hugo][repository]] for the ~ox-hugo~ package for more
     information.

***** ~use-package~ Users

      #+BEGIN_SRC emacs-lisp
        (use-package ox-hugo
          :after ox)
      #+END_SRC

***** Spacemacs Users

      Use @@html:<kbd>@@ SPC f e d @@html:</kbd>@@ to open ~~/.spacemacs~ (or
      ~~/.spacemacs/init.el~) and within the ~dotspacemacs/layers~ function, add or
      update an entry to the ~dotspacemacs-configuration-layers~ list like so:

      #+BEGIN_SRC emacs-lisp
        (org :variables
             org-enable-hugo-support t)
      #+END_SRC

      Restart Emacs or use @@html:<kbd>@@ SPC f e R @@html:</kbd>@@ to reload your
      configuration on-the-fly. If you already have an entry for the ~org~ layer,
      just include the variable ~org-enable-hugo-support~ with value ~t~.

**** Workflow
***** Project Structure

      I'm working within a vanilla Hugo project with the following structure,
      similar to what you'd see right after a ~hugo new site~ command:

      #+BEGIN_SRC sh
        $ tree -d -L 2
        .
         archetypes
         content
          blog
          pages
         data
         layouts
         static
          images
         themes
             hugo-redlounge
      #+END_SRC

      My ~blog.org~ file sits at the root of my repository, but could be placed
      nearly anywhere within and re-targeted with the ~HUGO_BASE_DIR~ setting.
      Subtrees get exported to a subdirectory of ~content~ based on their
      ~EXPORT_HUGO_SECTION~ property.

***** File Structure

      There are several options for organizing the ~.org~ file you store your
      blog posts and pages in, but here's a single-file structure that works
      well for me.

****** Global settings and metadata

       #+BEGIN_SRC org -n 1
         ,#+STARTUP: content
         ,#+AUTHOR: Shane Sveller
         ,#+HUGO_BASE_DIR: .
         ,#+HUGO_AUTO_SET_LASTMOD: t
       #+END_SRC

       Line 1 is an ~org-mode~ setting that tells Emacs that upon opening this
       file, default to showing all headings and subheadings but not the inner
       content until @@html:<kbd>@@ TAB @@html:</kbd>@@ is pressed while the
       pointer is on a particular heading.

       Line 2 sets my global author information, which propagates into each post
       and page I manage with this ~.org~ file.

       Line 3 tells ~ox-hugo~ that the current ~.org~ file is located in the
       root of the overall Hugo project, which means that exported data will
       be saved into the ~content~ directory and appropriate subdirectory that
       reside next to the ~.org~ file. Relative and absolute paths both work here.

       Finally line 4 tells ~ox-hugo~ to update the ~lastmod~ property of each
       exported item to match the current time and date, which can be reflected
       on your site in various ways based on your theme and configuration.

****** Creating a page
       :PROPERTIES:
       :END:

       #+BEGIN_SRC org -n 5
         ,* Pages
           :PROPERTIES:
           :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :noauthor true :nocomment true :nodate true :nopaging true :noread true
           :EXPORT_HUGO_MENU: :menu main
           :EXPORT_HUGO_SECTION: pages
           :EXPORT_HUGO_WEIGHT: auto
           :END:
       #+END_SRC

       My ~.org~ file has a dedicated top-level Org heading to contain my ~Page~
       content, and this heading sets a number of shared *properties* that are
       inherited by the individual sub-headings representing each page.

       Line 7 includes multiple key-value pairs that get inserted as-is into the
       [[https://gohugo.io/content-management/front-matter/#front-matter-variables][Hugo
       front matter]]. It largely disables all the "frills" one might typically
       associate with a regular blog post - commenting, pagination, metadata, etc.

       Line 8 indicates that Hugo should include a link to this content on the
       ~main~ menu of my site, which is currently displayed on the left sidebar
       of every page.

       Line 9 tells ~ox-hugo~ to export the files into the ~/content/pages~
       subdirectory of my Hugo project, which has a slightly different Hugo
       template file than a standard blog post.

       Line 10 tells ~ox-hugo~ to manage the ~weight~ property of the Hugo
       front matter data. It will calculate the appropriate relative numbers to
       fill in during the export process.

       #+BEGIN_SRC org -n12
         ,** Page Title
            :PROPERTIES:
            :EXPORT_FILE_NAME: page-title
            :END:

            Page content
       #+END_SRC

       To create a new ~page~ on my Hugo site, I insert a new sub-heading under
       the ~Pages~ heading from the snippet just above. That heading's title is
       somewhat arbitrary, but this sub-heading will directly inform the ~title~
       of the exported content.

       Line 14 demonstrates the first truly required property,
       ~EXPORT_FILE_NAME~, with tells ~ox-hugo~ what filename under
       ~/content/pages~ to export this sub-tree to. Under my current settings
       this also directly determines the actual path portion of the resulting
       URL. For example, this one would be visible at ~/pages/page-title/~.

       Pages can include fairly arbitrary content below the sub-heading,
       including further sub-headings to break up a longer page or post. You can
       include links, images, and formatting, all using standard Org syntax.

****** Creating posts
       :PROPERTIES:
       :END:

       #+BEGIN_SRC org -n 19
         ,* Posts
           :PROPERTIES:
           :EXPORT_HUGO_SECTION: blog
           :END:
       #+END_SRC

       As with Pages above, I create a top-level Org heading to contain my
       standard blog posts.

       Line 20 configures ~ox-hugo~ to export any sub-headings to
       ~/content/blog~ in my Hugo project, versus ~pages~ above.

      #+BEGIN_SRC org -n 23
        ,** Topic                                                             :@topic:
      #+END_SRC

      I sort my posts into categories by topic and create sub-headings for each
      topic, and assign Org tags to each sub-heading that are prefixed with ~@~.
      Org tags on a post that have an ~@~ prefix will generate a ~category~
      entry in the exported front matter, which is one of the [[https://gohugo.io/content-management/taxonomies/#hugo-taxonomy-defaults][default taxonomies]]
      built into a new Hugo project. Org tags are inherited from parent headings
      by sub-headings, so all further subheadings under this subheading will
      include the ~@topic~ tag.

      #+BEGIN_SRC org -n 24
        ,*** DONE Post Title                                               :post:tags:
            CLOSED: [2017-12-19 Tue 17:00]
            :PROPERTIES:
            :EXPORT_DATE: 2017-12-19
            :EXPORT_FILE_NAME: post-title-in-slug-form
            :END:
      #+END_SRC

      This sub-heading begins a new post, and is marked as *DONE* in Org syntax
      with a *CLOSED* timestamp. It also has Org tags named ~post~ and ~tags~
      which will be inserted into the exported front matter as ~tags~. It
      includes an ~EXPORT_DATE~ property, which would be used as the post's
      publication date in the absense of the *CLOSED* timestamp on line 25.
      Finally it includes the same ~EXPORT_FILE_NAME~ property as mentioned
      above under Page management.

      #+BEGIN_SRC org -n31
        Content

        More content

        ,#+BEGIN_SRC bash -l 7 :hl_lines 8
          echo 'Some source code content'
          echo 'This line will be highlighted'
          echo "This one won't"
        ,#+END_SRC
      #+END_SRC

      This snippet demonstrates the syntax needed to include a
      syntax-highlighted code snippet within a post. You can quickly start a
      code block with @@html:<kbd>@@ < s TAB @@html:</kbd>@@.

      If you append a valid language to ~#+BEGIN_SRC~, and your copy of Emacs
      has an associated major mode that is named ~$language-mode~, you'll get
      automatic syntax highlighting while composing the post, and the exported
      markdown will include either the ~highlight~ [[https://gohugo.io/content-management/syntax-highlighting/#highlight-shortcode][shortcode]] or [[https://gohugo.io/content-management/syntax-highlighting/#highlight-in-code-fences][Markdown "code
      fences"]]. As an added bonus, you can use ~org-edit-special~ (@@html:<kbd>@@
      , ' @@html:</kbd>@@ for Spacemacs or @@html:<kbd>@@ C-c ' @@html:</kbd>@@
      for vanilla Emacs) to open a new popover window that lets you edit that
      code snippet in a separate Emacs buffer. This will behave nearly
      identically to editing a standalone file with that major mode, including
      any extra behavior like auto-complete, linting, etc.

****** Excluding/heading sub-headings from export

       On some posts I like to create a private space to jot down ad hoc notes,
       research and reference links, unrefined code snippets, etc. that
       shouldn't appear in the final product but are useful to me during the
       writing process. By configuring the ~org-export-exclude-tags~ variable,
       or an ~EXCLUDE_TAGS~ file variable, then inserting a matching Org tag on
       a sub-heading, that content will not appear in the exported Markdown or
       in the published post, but will remain intact in the original ~.org~
       file. In my case, it's a ~:noexport:~ tag.

****** Automatic export on save

       The ox-hugo site includes [[https://ox-hugo.scripter.co/doc/auto-export-on-saving/][great documentation]] for adding a local variable
       to your ~.org~ file to enable automatic "what I mean" export whenever you
       save the file.

       The resulting syntax after following these instructions is:

       #+BEGIN_SRC org -n 51
         ,* Footnotes
         ,* COMMENT Local Variables                                           :ARCHIVE:
         # Local Variables:
         # eval: (add-hook 'after-save-hook #'org-hugo-export-wim-to-md-after-save :append :local)
         # eval: (auto-fill-mode 1)
         # End:
       #+END_SRC

****** Full Sample
       :PROPERTIES:
       :END:

      #+BEGIN_SRC org -n 1 :hl_lines 3,4,7,9,10,21,24-29,35-39,44,51-56
        ,#+STARTUP: content
        ,#+AUTHOR: Shane Sveller
        ,#+HUGO_BASE_DIR: .
        ,#+HUGO_AUTO_SET_LASTMOD: t
        ,* Pages
          :PROPERTIES:
          :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :noauthor true :nocomment true :nodate true :nopaging true :noread true
          :EXPORT_HUGO_MENU: :menu main
          :EXPORT_HUGO_SECTION: pages
          :EXPORT_HUGO_WEIGHT: auto
          :END:
        ,** Page Title
           :PROPERTIES:
           :EXPORT_FILE_NAME: page-title
           :END:

           Page content

        ,* Posts
          :PROPERTIES:
          :EXPORT_HUGO_SECTION: blog
          :END:
        ,** Topic                                                             :@topic:
        ,*** DONE Post Title                                               :post:tags:
            CLOSED: [2017-12-19 Tue 17:00]
            :PROPERTIES:
            :EXPORT_DATE: 2017-12-19
            :EXPORT_FILE_NAME: post-title-in-slug-form
            :END:

            Content

            More Content

            ,#+BEGIN_SRC bash -l 7 :hl_lines 8
              echo 'Some source code content'
              echo 'This line will be highlighted'
              echo "This one won't"
            ,#+END_SRC

        ,**** Post Sub-Heading
             This is another section within the post.

        ,*** TODO Draft Post Title
            :PROPERTIES:
            :EXPORT_FILE_NAME: draft-post-title
            :END:

            This article *will* be exported but will be marked ~draft = true~ in the front matter.

        ,* Footnotes
        ,* COMMENT Local Variables                                           :ARCHIVE:
        # Local Variables:
        # eval: (add-hook 'after-save-hook #'org-hugo-export-wim-to-md-after-save :append :local)
        # eval: (auto-fill-mode 1)
        # End:
      #+END_SRC

***** Marking a post as a Draft

      To create a new draft post, add a new heading or subheading, and set it to
      *TODO* status, perhaps via ~M-x org-todo~ or @@html:<kbd>@@ C-c C-t
      @@html:</kbd>@@.

      *TODO* status ensures that the post will be rendered to Markdown with
      ~draft = true~ in its frontmatter, which configures Hugo itself to prevent
      a premature publish of the article to your live site unless specifically
      instructed to include draft content.

      /A heading without *TODO* or *DONE* is *not* considered a draft/.

***** Publishing a Draft

      To publish a draft post, toggle its *TODO* state to *DONE*. If you have
      ~org-log-done~ set to ~'time~, toggling to *DONE* automatically adds a
      *CLOSED:* timestamp that will be respected in favor of ~EXPORT_DATE~
      property for setting the ~date~ in the rendered post's front matter.

***** Creating a draft with =org-capture=                          :noexport:

***** Optional: Live reload without a separate shell tab
      :PROPERTIES:
      :CUSTOM_ID: prodigy-hugo-service
      :END:

      If you enable the ~prodigy~ layer in Spacemacs, or install the ~Prodigy~
      package manually, you can define a process in your
      ~dotspacemacs/user-config~ function like so:

      #+BEGIN_SRC emacs-lisp -n1
        (prodigy-define-service
          :name "Hugo Personal Blog"
          :command "/usr/local/bin/hugo"
          :args '("server" "-D" "--navigateToChanged" "-t" "hugo-redlounge")
          :cwd "~/src/shanesveller-dot-com"
          :tags '(personal)
          :stop-signal 'sigkill
          :kill-process-buffer-on-stop t)
      #+END_SRC

      Then, to manage the process while editing with Emacs, I use @@html:<kbd>@@ SPC a
      S @@html:</kbd>@@ to open the Prodigy buffer, highlight the service entry, and
      use @@html:<kbd>@@ s @@html:</kbd>@@ to start the process, @@html:<kbd>@@ S
      @@html:</kbd>@@ to stop the service, and @@html:<kbd>@@ $ @@html:</kbd>@@ to
      view process output. @@html:<kbd>@@ q @@html:</kbd>@@ will back out of any
      Prodigy-generated buffers.

***** TODO Bonus: Publishing Your Blog With Netlify                :noexport:

**** Room for Improvement                                          :noexport:

     /Ed: These are candidates for inclusion before this post goes live./

     - Linking to headings, other posts, and headings in other posts
       (~CUSTOM_ID~ property seems to work within a document)
     - Emacs-lisp function to view Netlify preview URL by Git SHA
     - Emacs-lisp function to open your browser when opening the ~.org~ file and
       Hugo is running
     - [[https://ox-hugo.scripter.co/doc/images-in-content/][Screenshot capture workflow]]
     - [[http://orgmode.org/worg/org-contrib/org-protocol.html][Org-protocol workflow]]
     - [[https://ox-hugo.scripter.co/doc/org-capture-setup/][Org-capture templates]]
     - CI workflow if not using the Netlify / GitHub webhooks integration

**** Software/Tool Versions
     :PROPERTIES:
     :CUSTOM_ID: ox-hugo-software-tool-versions
     :END:

     | Software  |       Version |
     |-----------+---------------|
     | Emacs     |        25.3.1 |
     | Spacemacs |       0.300.0 |
     | Org       |         9.1.2 |
     | Hugo      |        0.31.1 |
     | ox-hugo   | 20171026.1402 |
     | prodigy   | 20170816.1114 |

**** Emacs Lisp Snippets

     Here's a snippet that can build off of [[#prodigy-hugo-service][the Prodigy service snippet]] to
     automatically visit your local Hugo server in a browser once it's running.

     I'm still learning emacs-lisp, and will probably find in the future that
     this style doesn't suit me, particularly the trailing parentheses.

     I'd also like to investigate ~defcustom~ to allow these default values to
     be more configurable.

     #+BEGIN_SRC emacs-lisp
       (defun browse-hugo-maybe ()
         (interactive)
         (let ((hugo-service-name "Hugo Personal Blog")
               (hugo-service-port "1313"))
           (if (prodigy-service-started-p (prodigy-find-service hugo-service-name))
               (progn
                 (message "Hugo detected, launching browser...")
                 (browse-url (concat "http://localhost:" hugo-service-port))))))
     #+END_SRC

**** Credits

Thank you to [[https://twitter.com/jrnt30][Justin Nauman]] for great feedback on an early version of this
article. Any remaining flaws are my own.

**** Reference Links                                               :noexport:
     - https://www.netlify.com/docs/continuous-deployment/#common-configuration-directives
     - https://github.com/kaushalmodi/ox-hugo/blob/dffb7e970f33959a0b97fb8df267a54d01a98a2a/ox-hugo.el#L2570
**** Emacs-Lisp Scratch Pad                                        :noexport:

     #+BEGIN_SRC emacs-lisp
       (defun browse-hugo-maybe ()
         (interactive)
         (let ((hugo-service-name "Hugo Personal Blog")
               (hugo-service-port "1313"))
           (if (prodigy-service-started-p (prodigy-find-service hugo-service-name))
               (progn
                 (message "Hugo detected, launching browser...")
                 (browse-url (concat "http://localhost:" hugo-service-port))))))

       (defun current-magit-commit ()
         (interactive)
         (progn
           (message "Current file: %s" (buffer-file-name))
           (message "Current file status: %s" (vc-working-revision (buffer-file-name)))
           (let '(short-name "shanesveller-dot-com")
             (browse-url (format "https://%s--%s.netlify.com" (truncate-string-to-width (vc-working-revision (buffer-file-name)) 24) short-name))
             )
           )
         )

       ;; https://5a3998c20b79b7514937073d--shanesveller-dot-com.netlify.com/
       ;; 5a3998c20b79b7514937073d

       (defun toolbox ()
         (interactive)

         (save-excursion
           (org-back-to-heading :invisible-ok)
           (let* (
                  (this-element (org-element-at-point))
                  (prop-name :EXPORT_FILE_NAME)
                  (element-prop (org-element-property prop-name this-element))
                  )
             (message "%s" element-prop)
             )
           )
         )

       (defun format-subtree-permalink (date filename)
         (let* (
                (split-date (split-string date "-"))
                (date-year (nth 0 split-date))
                (date-month (nth 1 split-date))
                (date-day (nth 2 split-date))
                )
           (message "%s/%s/%s/%s" date-year date-month date-day filename)
           )
         )

       (defun destructure-test (date filename)
         (require 'cl)
         (destructuring-bind (date-year date-month date-day)
             (split-string date "-")
           (message "%s/%s/%s/%s" date-year date-month date-day filename)
           )
         )

       ;; (destructure-test "2017-12-29" "my-filename")

       ;; https://5a3af02a4c4b932e03d474a9--shanesveller-dot-com.netlify.com/
       (defun browse-netlify-branch-deploy (git-sha site-name &optional sub-path)
         (let* (
                (netlify-proto "https")
                (netlify-hostname "netlify.com")
                (netlify-url-format "%s://%s--%s.%s%s")
                )
           ;; (browse-url (format netlify-url-format netlify-proto git-sha site-name netlify-hostname (or sub-path "")))
           (message netlify-url-format netlify-proto git-sha site-name netlify-hostname (or sub-path ""))
           )
         )

       (browse-netlify-branch-deploy "5a3af02a4c4b932e03d474a9" "shanesveller-dot-com")

       ;; https://www.shanesveller.com/blog/2017/12/19/blogging-with-org-mode-and-ox-hugo/
       (defun my/preview-post-on-netlify ()
         (interactive)

         (save-excursion
           (ignore-errors
             (org-back-to-heading :invisible-ok))
           (let* (
                  (post-element (org-hugo--get-valid-subtree))
                  (post-filename (org-element-property :EXPORT_FILE_NAME post-element))
                  ;; (upstream (magit-get-upstream-remote))
                  ;; (remote-url (magit-git-string "remote" "get-url" upstream))
                  ;; (remote-components (split-string remote-url "/"))
                  ;; (raw-repo (car (last remote-components)))
                  ;; (repo (replace-regexp-in-string "\.git$" "" raw-repo))
                  (branch (magit-get-current-branch))
                  (upstream-remote (magit-get-upstream-remote branch))
                  (upstream-branch (magit-get-upstream-branch branch))
                  ;; (sanitized-branch (url-hexify-string branch))
                  (git-sha (magit-rev-parse-safe upstream-branch))
                  (sub-path (format "/blog/%s/%s/%s/%s/" "2017" "12" "19" "blogging-with-org-mode-and-ox-hugo"))
                  )
             (message "%s/%s/%s/%s" branch upstream-remote upstream-branch (magit-get-upstream-ref branch))
             ;; (message "%s" (browse-netlify-branch-deploy git-sha "shanesveller-dot-com" sub-path))
             )
           )
         )
     #+END_SRC

** Productivity                                               :@productivity:
*** TODO Managing shell dotfiles with thoughbot's rcm  :@shells:dotfiles:rcm:
    :PROPERTIES:
    :EXPORT_FILE_NAME: managing-shell-dotfiles-with-thoughtbots-rcm
    :END:

** Terraform                            :@terraform:infrastructure__as__code:
   :PROPERTIES:
   :VISIBILITY: children
   :END:
*** DONE Managing GitLab groups and projects with Terraform          :gitlab:
    CLOSED: [2017-12-17 Sun 11:26]
    :PROPERTIES:
    :EXPORT_DATE: 2017-12-17
    :EXPORT_FILE_NAME: managing-gitlab-with-terraform
    :END:

    I've begun using GitLab to host some of my personal projects on my own
    domain, sometimes as a mirror of a GitHub repository and sometimes as the
    primary home of the project.

    <!--more-->

**** Configuring the provider

     The following Terraform syntax can be used with the public/commercial
     GitLab.com service or with a self-hosted installation, as long as you have
     network connectivity and a token with the correct permissions. I'm using
     the latter.

     In my case, I used a *Personal Access Token* associated with my individual
     administrative account, with these permissions:

     - ~api~
     - ~read_user~

     #+BEGIN_SRC hcl
       variable "gitlab_token" {
         type    = "string"
         default = "hunter2"
       }

       variable "gitlab_url" {
         type    = "string"
         default = "https://gitlab.mydomain.com/api/v4/"
       }

       provider "gitlab" {
         base_url = "${var.gitlab_url}"
         token    = "${var.gitlab_token}"
         version  = "~> 1.0.0"
       }
     #+END_SRC

     If you'd like to keep these out of your source code, Terraform also allows
     setting variables in shell environment variables by prefixing them with
     ~TF_VAR_~, as in ~TF_VAR_gitlab_token~ and ~TF_VAR_gitlab_url~. You can
     manage these manually or with a tool like [[https://direnv.net/][direnv]],
     and keep the latter's ~.envrc~ file in your ~.gitignore~.

**** Creating a group

     #+BEGIN_SRC hcl
       resource "gitlab_group" "blogs" {
         name        = "blogs"
         path        = "blogs"
         description = "Public blog repositories"
       }
     #+END_SRC

***** Creating a nested group

      I have a group on my GitLab site for ~infrastructure~ projects, and a
      nested group on my site for [[https://helm.sh/][Helm]] charts within that ~infrastructure~
      group. Here's the Terraform code that manages those two groups and their
      relationship:

      #+BEGIN_SRC hcl
        resource "gitlab_group" "infrastructure" {
          name        = "infrastructure"
          path        = "infrastructure"
        }

        resource "gitlab_group" "helm-charts" {
          name        = "helm-charts"
          path        = "helm-charts"
          parent_id   = "${gitlab_group.infrastructure.id}"
        }
      #+END_SRC

      Projects created within this child group will appear on the site at
      paths that look like ~/infrastructure/helm-charts/foo-chart~.

**** Creating a project within a group

     Here's an example, a mirror of my public blog that is hosted on GitHub as
     well. Because of the nature of its contents, I've disabled most of the
     extra features offered by GitLab for this particular repository.

     #+BEGIN_SRC hcl :hl_lines 2,7
       resource "gitlab_project" "blogs-shanesveller-dot-com" {
         name                   = "shanesveller-dot-com"
         default_branch         = "master"
         description            = ""
         issues_enabled         = false
         merge_requests_enabled = false
         namespace_id           = "${gitlab_group.blogs.id}"
         snippets_enabled       = false
         visibility_level       = "public"
         wiki_enabled           = false
       }
     #+END_SRC

     With the highlighted lines in place, the repository path on the site
     becomes ~/blogs/shanesveller-dot-com~.

**** Closing Comments

     The GitLab provider as of 1.0.0 is missing some API coverage for what
     GitLab offers, and has some bugs associated with things like a project's
     default branch. Often I use ~git-flow~ and want to set a project's default
     branch to ~develop~, but that feature does not currently seem to work
     reliably due to
     [[https://github.com/terraform-providers/terraform-provider-gitlab/pull/41][this
     code typo]].

**** Software/Tools Versions
     :PROPERTIES:
     :CUSTOM_ID: gitlab-terraform-software-tools-versions
     :END:

     | Software                  | Version |
     |---------------------------+---------|
     | GitLab                    |  10.2.4 |
     | Terraform                 |  0.10.7 |
     | Terraform GitLab Provider |   1.0.0 |

**** Reference Links                                               :noexport:

     - https://www.terraform.io/docs/providers/gitlab/index.html

* Page Ideas                                                       :noexport:
  :PROPERTIES:
  :VISIBILITY: content
  :END:
** Networking                                                   :@networking:
   :PROPERTIES:
   :VISIBILITY: children
   :END:
*** TODO Home Network
    :PROPERTIES:
    :EXPORT_AUTHOR: Shane Sveller
    :EXPORT_FILE_NAME: home-network
    :END:

My home network is largely made up of Ubiquiti Unifi equipment.

**** Router

My router is a UBNT USG 3-port. I also own a 4-port USG Pro but cannot currently
tolerate the fan noise in an apartment, so that's still in the box.

**** Switching

I have a UBNT 24-port 250W POE switch for my main hub, as well as a UBNT 8-port
switch with POE passthrough for my TV stand so I can hard-wire my game consoles and
media devices.

* Post Ideas                                                       :noexport:

** Elixir                                                           :@elixir:
   :PROPERTIES:
   :VISIBILITY: children
   :END:
*** TODO Managing Elixir runtime version with Nix                :elixir:nix:
    :PROPERTIES:
    :EXPORT_AUTHOR: Shane Sveller
    :EXPORT_DATE: 2017-12-15
    :EXPORT_FILE_NAME: managing-elixir-runtime-version-with-nix
    :END:

 I've experimented recently with managing multiple versions of Erlang and Elixir with Nix.

 <!--more-->

**** Software/Tool Versions

 | Software | Verison |
 |----------+---------|
 | OSX      | 10.12.6 |
 | Nix      | 1.11.16 |

**** Installation

 #+BEGIN_SRC shell-script
 brew cask install nix
 #+END_SRC

**** Getting Started

**** References

** Emacs                                                             :@emacs:
   :PROPERTIES:
   :VISIBILITY: children
   :END:
*** TODO Spaced repitition with =org-drill=                       :education:
    :PROPERTIES:
    :EXPORT_DATE: 2017-12-17
    :EXPORT_FILE_NAME: org-drill
    :END:

    My team at [[https://www.raise.com/][work]] has previously used
    [[http://orgmode.org/worg/org-contrib/org-drill.html][org-drill]] to study
    less-familiar subjects, initially focused on Kubernetes during our early
    adoption process. Its documentation is largely excellent, but here's a few
    extra details we've learned over time.

**** Installation

     #+BEGIN_SRC emacs-lisp
       (with-eval-after-load 'org
         (require 'cl)
         (require 'org-drill))
     #+END_SRC

**** Usage
***** Creating cards
****** Single File
       Here's what the raw ~org~ source looks like:

       #+BEGIN_SRC org
         ,* Cards

         ,** Card 1                                                             :drill:

         ,*** Card 1 Answer
       #+END_SRC
****** Directory of Files
**** Software/Tools Versions
     :PROPERTIES:
     :CUSTOM_ID: org-drill-software-tools-versions
     :END:

     | Software  | Version |
     |-----------+---------|
     | Emacs     |  25.3.1 |
     | Spacemacs | 0.300.0 |
     | Org       |   9.1.2 |
**** Reference Links                                               :noexport:
     - http://orgmode.org/worg/org-contrib/org-drill.html
*** TODO Presentations with org-mode and org-reveal :org:mode:presentation:reveal_js:slideshow:
    :PROPERTIES:
    :EXPORT_DATE: 2017-12-26
    :EXPORT_FILE_NAME: presentations-with-org-mode-and-org-reveal
    :END:

** Kubernetes                                                   :@kubernetes:
   :PROPERTIES:
   :VISIBILITY: children
   :END:
*** TODO Allowing HTTP traffic with nginx-ingress
*** TODO Securing HTTPS traffic with cert-manager
*** TODO Monitoring GKE with CoreOS' Prometheus Operator :coreos:monitoring:prometheus:gke:kubernetes:
    :PROPERTIES:
    :EXPORT_AUTHOR: Shane Sveller
    :EXPORT_FILE_NAME: monitoring-gke-with-coreos-prometheus-operator
    :EXPORT_HUGO_WEIGHT: auto
    :END:

**** Background

 [[https://prometheus.io/][Prometheus]] is all the rage in the Kubernetes community, especially after
 becoming a Cloud Native Computing Foundation [[https://www.cncf.io/projects/][hosted project]].

 CoreOS has a project called [[https://github.com/coreos/prometheus-operator][prometheus-operator]] which helps manage instances
 of a Prometheus server, or its compatriot AlertManager, via Kubernetes manifests.

**** Getting Started

 I've chosen to install the Operator via the project's provided [[https://github.com/coreos/prometheus-operator/tree/v0.15.0/helm/prometheus-operator][Helm Chart]].

 First, install CoreOS' Helm repository

 #+BEGIN_SRC shell-script
   helm init --client-only
   helm repo add coreos https://s3-eu-west-1.amazonaws.com/coreos-charts/stable/
 #+END_SRC

 I've also provided some customized values:

 #+BEGIN_SRC yaml
   global:
     ## Hyperkube image to use when getting ThirdPartyResources & cleaning up
     ##
     hyperkube:
       repository: quay.io/coreos/hyperkube
       # https://quay.io/repository/coreos/hyperkube?tag=latest&tab=tags
       tag: v1.8.4_coreos.0
       pullPolicy: IfNotPresent

   ## Prometheus-operator image
   ##
   image:
     repository: quay.io/coreos/prometheus-operator
     # https://quay.io/repository/coreos/prometheus-operator?tag=latest&tab=tags
     tag: v0.15.0
     pullPolicy: IfNotPresent
 #+END_SRC

 Finally, I install the chart with my supplied values in a ~monitoring~ namespace:

 #+BEGIN_SRC shell-script
   helm install --name prometheus-operator \
        --namespace monitoring \
        --values prometheus-operator-values.yaml \
        coreos/prometheus-operator
 #+END_SRC

**** Using kube-prometheus for basic cluster metrics

 #+BEGIN_SRC shell-script
   helm install --name kube-prometheus \
        --namespace monitoring \
        --values kube-prometheus-values.yaml \
        coreos/kube-prometheus
 #+END_SRC

**** Software/Tool Versions

 | Project                   |     Version |
 |---------------------------+-------------|
 | Google Cloud SDK          |     182.0.0 |
 | Kubernetes                | 1.8.3-gke.0 |
 | Helm                      |       2.7.2 |
 | Prometheus Operator       |      0.15.0 |
 | Prometheus Operator Chart |       0.0.7 |
 | Prometheus                |       1.8.2 |

*** TODO Building and testing software with Jenkins on Kubernetes
** Shell Programming                                                :@shells:
   :PROPERTIES:
   :VISIBILITY: children
   :END:
*** Fish Shell                                                        :@fish:
    :PROPERTIES:
    :VISIBILITY: children
    :END:
**** TODO Getting your feet wet with Fish Shell
     :PROPERTIES:
     :EXPORT_AUTHOR: Shane Sveller
     :EXPORT_FILE_NAME: getting-your-feet-wet-with-fish-shell
     :EXPORT_HUGO_WEIGHT: auto
     :END:

***** Software/Tool Versions

 | Software   | Version |
 |------------+---------|
 | OSX        | 10.12.6 |
 | iTerm 2    |   3.1.5 |
 | Fish       |   2.7.0 |
 | Oh My Fish |       6 |

***** Installation

 #+BEGIN_SRC shell-script
   brew install fish
 #+END_SRC

 Now, install oh-my-fish via ~git~ because curl-bash is for suckers!

 #+BEGIN_SRC shell-script
   git clone https://github.com/oh-my-fish/oh-my-fish
   cd oh-my-fish
   bin/install --offline
 #+END_SRC

* Footnotes
* COMMENT Local Variables                                                   :ARCHIVE:
  # Local Variables:
  # org-hugo-auto-export-on-save: t
  # End:
